# For more information on how to use this pipeline please refer to:
# http://tardis-sn.github.io/tardis/development/continuous_integration.html

trigger: none
pr: [ master ]

variables:
  system.debug: false

jobs:
  - job: report
    pool:
      vmImage: 'ubuntu-latest'

    steps:
      - template: templates/default.yml
        parameters:
          fetchRefdata: true

      - bash: |
          source activate tardis
          conda install bokeh -c conda-forge --no-update-deps --yes
        displayName: 'Install Bokeh package'

      - bash: |
          cd $(tardis.dir)
          source activate tardis
          python setup.py test --args='--tardis-refdata=$(refdata.dir) --generate-reference'
        displayName: 'Generate new reference data'

      - bash: |
          cd $(refdata.dir)
          source activate tardis
          git remote add upstream https://github.com/tardis-sn/tardis-refdata.git
          git fetch upstream
          git fetch upstream "+refs/pull/*/head:refs/remotes/upstream/pr/*"
          cd notebooks
          jupyter nbconvert ref_data_compare.ipynb --to html --execute --allow-errors --ExecutePreprocessor.timeout=6000
        displayName: 'Generating report'
        condition: false

      - task: PublishPipelineArtifact@1
        inputs:
          targetPath: '$(refdata.dir)/notebooks/ref_data_compare.html'
          artifactName: 'report'
        condition: succeeded()

      - bash: |
          ls -lR /tmp
          echo
        condition: succeededOrFailed()
        displayName: 'Check files in /tmp'

# Keep this line, is useful for testing without changing the notebook.
# sed -i "s/ref2_hash='upstream\/pr\/24'/ref1_hash='c998f44', ref2_hash='master'/g" ref_data_compare.ipynb